# Math Tutor LLM - Weights & Biases Course Submission

This project demonstrates fine-tuning a smaller LLM (TinyLlama-1.1B) to act as a math tutor, with full Weights & Biases integration for experiment tracking. The model is fine-tuned to provide step-by-step explanations for math problems across various topics.

## Project Overview

- **Task**: Fine-tune an LLM to act as a math tutor
- **Base Model**: TinyLlama-1.1B-Chat-v1.0
- **Fine-tuning Method**: LoRA (Low-Rank Adaptation)
- **Dataset**: Custom dataset combining math problems from various sources
- **Tracking**: Full W&B integration for both training and inference
- **Deployment**: FastAPI + Gradio interface

## Link to W&B Report

[wandb report](https://wandb.ai/islam-hachimi2003-student/math-tutor-llm/reports/Finetuning-TinyLlama-1-1B-Chat-v1-0--VmlldzoxMjM0NTM3Mg?accessToken=67civ1b5wg06qrx1mbz9mdsxjro08zyauju49f4d1y2xj4adra1hjgopfdw6asvx)